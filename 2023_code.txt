import pandas as pd
import pyodbc as msql
import numpy as np
from pivottablejs import pivot_ui
import math
from sklearn.linear_model import LinearRegression
import snowflake.connector

model = LinearRegression()
conn = msql.connect(driver='{SQL Server}', 
            server='vapafpdf_db.tdisf-prd.eu-west-1.aws.private-pmideep.biz,49600', 
            database='VP_DataMart',
            trusted_connection='yes')
conn2 = snowflake.connector.connect(
    user="ftozoglu@PMINTL.NET",
    account="pl47603.eu-west-1",
    authenticator="externalbrowser",
    warehouse='WH_PRD_REPORTING',
    role='PMI_EDP_SPK_SNFK_PMI_FDF_PRD_DATAANALYST_IMDL',
    database = "DB_FDF_PRD"
)

time_dim = ['Year']
brand_attributes = ['Taste','Thickness','Flavor','Length'] 
IATA_List = ['CJU']
dimension = ['Flavor','Taste','Thickness','Length'] 
domestic_dimensions = ['Market','EBROMId','EBROM','Taste','Thickness', 'Flavor','Length']
current_year = 2023
previous_year = current_year-1
theyearbefore = previous_year-1

MC_per_Product = pd.read_pickle('datasource/MC_per_Product.pkl')
cat_a_df_vols = pd.read_pickle('datasource/cat_a_df_vols.pkl')

DF_Vols_w_Financials = cat_a_df_vols.merge(MC_per_Product[['DF_Market','Location','CR_BrandId',f"{previous_year} MC",
                                            f"{previous_year} NOR",f"{current_year} MC",f"{current_year} NOR"]], 
                                           how = 'left', on = ['DF_Market','Location','CR_BrandId']).fillna(0)
DF_Vols_w_Financials = DF_Vols_w_Financials[DF_Vols_w_Financials[f"{current_year} Volume"]>0]

DF_Vols_w_Financials['LYRevenueAvg'] = np.where(DF_Vols_w_Financials[f"{previous_year}Month"] == 0, 0, 
                            round(DF_Vols_w_Financials[f"{previous_year} Revenue"] / DF_Vols_w_Financials[f"{previous_year}Month"],0))
DF_Vols_w_Financials['CYRevenueAvg'] = np.where(DF_Vols_w_Financials[f"{current_year}Month"] == 0, 0, 
                                         round(DF_Vols_w_Financials[f"{current_year} Revenue"] / DF_Vols_w_Financials[f"{current_year}Month"],0))

DF_Vols_w_Financials['Growth'] = (DF_Vols_w_Financials['CYRevenueAvg']-DF_Vols_w_Financials['LYRevenueAvg']) / DF_Vols_w_Financials['LYRevenueAvg']

DF_Vols_w_Financials['Margin'] = np.where(
                                        DF_Vols_w_Financials[f"{current_year} NOR"]<=0,0,
                                        ((DF_Vols_w_Financials[f"{current_year} MC"] /DF_Vols_w_Financials[f"{current_year}Month"]) /  
                                        (DF_Vols_w_Financials[f"{current_year} NOR"] / DF_Vols_w_Financials[f"{current_year}Month"])))
pmi_margins = DF_Vols_w_Financials[DF_Vols_w_Financials['TMO'] == 'PMI']

pmi_margins['Margin_Volume'] = round((pmi_margins[f"{current_year} Volume"] * pmi_margins['Margin'].fillna(0)),0).astype(int)
pmi_margins = pmi_margins.groupby(['DF_Market','Location','Brand Family']).sum().reset_index()
pmi_margins = pmi_margins[['DF_Market','Location','Brand Family',f"{current_year} Volume",f"{current_year} MC",'Margin_Volume']]
pmi_margins['Brand Family Margin'] = pmi_margins['Margin_Volume'] / pmi_margins[f"{current_year} Volume"]

SKU_by_Vols_Margins =  DF_Vols_w_Financials.merge(pmi_margins[['DF_Market','Location','Brand Family','Brand Family Margin']],
                                                  how = 'left', on =['DF_Market','Location','Brand Family']).fillna(0)
SKU_by_Vols_Margins['Margin Comparison'] = np.where(
                                        SKU_by_Vols_Margins['Brand Family Margin']< SKU_by_Vols_Margins['Margin'], 1 , 0)

no_of_sku = DF_Vols_w_Financials.groupby(['DF_Market', 'Location'])['SKU'].count().reset_index()
no_of_sku = no_of_sku.rename(columns = {'SKU': 'TotalSKU'})
no_of_sku['GreenFlagSKU'] = (no_of_sku['TotalSKU']*0.05).apply(np.ceil)
no_of_sku['RedFlagSKU'] = round(no_of_sku['TotalSKU']*0.25 , 0)

gf = pd.DataFrame(columns=['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU', 'Item per Bundle', 
                           f"{previous_year} Volume", f"{current_year} Volume",f"{previous_year}Month", f"{current_year}Month", 
                           f"{previous_year} Revenue", f"{current_year} Revenue", f"{previous_year} MC", f"{previous_year} NOR", 
                           f"{current_year} MC", f"{current_year} NOR",  'LYRevenueAvg','CYRevenueAvg', 'Growth', 'Margin'])

for i in DF_Vols_w_Financials.Location.unique():

    DF_Vols = DF_Vols_w_Financials[DF_Vols_w_Financials['Location'] == i]
    green_flag1 = DF_Vols.sort_values(f"{current_year} Volume", ascending = False).head(no_of_sku[no_of_sku['Location'] == i].iloc[0,-2].astype('int'))
    green_flag1['Green1'] = 1 
    green_flag1 = green_flag1[green_flag1['TMO'] == 'PMI']
    gf = pd.concat([gf,green_flag1],ignore_index = True)


gf2 = pd.DataFrame(columns=['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU', 'Item per Bundle', 
                             f"{previous_year} Volume", f"{current_year} Volume",f"{previous_year}Month", f"{current_year}Month", 
                             f"{previous_year} Revenue", f"{current_year} Revenue", f"{previous_year} MC", f"{previous_year} NOR", 
                             f"{current_year} MC", f"{current_year} NOR",  'LYRevenueAvg','CYRevenueAvg', 'Growth', 'Margin'])

for i in DF_Vols_w_Financials.Location.unique():

    DF_Vols = SKU_by_Vols_Margins[SKU_by_Vols_Margins['Location'] == i]
    green_flag2 = DF_Vols.sort_values('Growth', ascending = False).head(no_of_sku[no_of_sku['Location'] == i].iloc[0,-2].astype('int'))
    green_flag2 = green_flag2[green_flag2['TMO'] == 'PMI']
    green_flag2 = green_flag2[green_flag2['Margin Comparison'] == 1]
    green_flag2['Green Flag2'] = 1
    gf2 = pd.concat([gf2,green_flag2],ignore_index = True)

green_list = pd.concat([gf,gf2])
green_list = green_list[['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle']]
green_list = green_list.drop_duplicates()
green_list['Green']  = 1

rf1 = pd.DataFrame(columns=['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle'])

for i in DF_Vols_w_Financials.Location.unique():
    Red_Vols = DF_Vols_w_Financials[DF_Vols_w_Financials['Location'] == i]
    red_flag1 = Red_Vols.sort_values(f"{current_year} Volume", ascending = True).head(no_of_sku[no_of_sku['Location'] == i].iloc[0,-1].astype('int'))
    red_flag1 = red_flag1[red_flag1['TMO'] == 'PMI']
    
    red_flag1_1 = Red_Vols.sort_values('Growth', ascending = True).head(no_of_sku[no_of_sku['Location'] == i].iloc[0,-1].astype('int'))
    red_flag1_1 = red_flag1_1[red_flag1_1['TMO'] == 'PMI']
    
    red_flag_intersection = np.intersect1d(red_flag1.CR_BrandId, red_flag1_1.CR_BrandId)
    
    red_flag1_2 =  pd.concat([red_flag1,red_flag1_1], ignore_index = True)
    red_flag1_2 = red_flag1_2[red_flag1_2['CR_BrandId'].isin(red_flag_intersection) ].drop_duplicates()
    red_flag1_2 = red_flag1_2[['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle']]
    
    rf1 = pd.concat([rf1,red_flag1_2], ignore_index = True)  


rf2 = pd.DataFrame(columns=['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle'])

for i in DF_Vols_w_Financials.Location.unique():
    
    red_flag2_1 = SKU_by_Vols_Margins[SKU_by_Vols_Margins['Location'] ==  i]
    red_flag2_1 = red_flag2_1.sort_values('Growth', ascending = True).head(no_of_sku[no_of_sku['Location'] == i].iloc[0,-1].astype('int'))
    red_flag2_1 = red_flag2_1[red_flag2_1['TMO'] == 'PMI']
    red_flag2_1 = red_flag2_1[red_flag2_1['Margin Comparison'] == 0]
    red_flag2_1 = red_flag2_1[['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle']]
    rf2 = pd.concat([rf2,red_flag2_1 ], ignore_index = True)

red_list = pd.concat([rf1, rf2], ignore_index = True).drop_duplicates()
red_list['Red'] = 1

green_red_list = green_list.merge(red_list, how = 'outer', on = ['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle']).fillna(0)
green_red_list['Check'] = np.where(green_red_list['Green'] != green_red_list['Red'], 'OK','Problem')
green_red_list = green_red_list[green_red_list['Check'] != 'Problem']
green_red_list['Status'] = np.where(green_red_list['Green'] == 1 , 'Green', 'Red')


category_a_0 = SKU_by_Vols_Margins[SKU_by_Vols_Margins['TMO'] == 'PMI']
category_a_1 = (category_a_0.merge(
    green_red_list[['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle','Status']], 
    how = 'left',on = ['DF_Market', 'Location', 'TMO', 'Brand Family', 'CR_BrandId', 'SKU','Item per Bundle'])).fillna(0)
total_sku = category_a_1.groupby(['DF_Market', 'Location'])['CR_BrandId'].count().reset_index()
total_sku = total_sku.rename(columns = {'CR_BrandId': 'TotalSKU'})
ct_green = category_a_1[category_a_1['Status'] == 'Green']
ct_green = ct_green.groupby(['DF_Market', 'Location'])['CR_BrandId'].count().reset_index()
ct_green = ct_green.rename(columns = {'CR_BrandId': 'GreenSKU'})
ct_red = category_a_1[category_a_1['Status'] == 'Red']
ct_red = ct_red.groupby(['DF_Market', 'Location'])['CR_BrandId'].count().reset_index()
ct_red = ct_red.rename(columns = {'CR_BrandId': 'RedSKU'})

ct_gr_red = ct_red.merge(ct_green, how = 'outer', on = ['DF_Market', 'Location'])

calculation_table = total_sku.merge(ct_gr_red, how = 'outer', on =  ['DF_Market', 'Location'])
calculation_table['RedSKU'] = calculation_table['RedSKU'].fillna(0).astype('int')
calculation_table['GreenSKU'] = calculation_table['GreenSKU'].fillna(0).astype(int)

location = []
score_a= []

for i in calculation_table.Location.unique() :
    
    ct = calculation_table[calculation_table['Location'] == i]
    score = ((ct['GreenSKU'].iloc[0] -(ct['RedSKU'].iloc[0] *2 )) / ct['TotalSKU'].iloc[0])*100
    location.append(i)
    score_a.append(score)

list_of_tuples = list(zip(location, score_a))
cat_a_scores = pd.DataFrame(list_of_tuples,columns=['Location','Score_A'] ).fillna(0)
cat_a_scores['ScaledScore'] = round((cat_a_scores['Score_A']-(-200))*(10/300),2)

SELMA_DF_map = pd.read_pickle('datasource/SELMA_DF_map.pkl')
df_vols = pd.read_pickle('datasource/cat_a_df_vols.pkl')
base_list= pd.read_pickle('datasource/base_list.pkl')
base_list = base_list[['DF_Market','Location','TMO', 'CR_BrandId', 'SKU', 'Item per Bundle']]

SELMA_DF_map = SELMA_DF_map.drop_duplicates(['CR_BrandId','Location'])
SELMA_DF_map['Length'] = np.where(SELMA_DF_map['Length'].isin(['REGULAR SIZE','REGULAR FILTER','SHORT SIZE','LONG FILTER','NAN']),'KS', 
                         np.where(SELMA_DF_map['Length'].isin(['LONGER THAN KS','100','LONG SIZE','EXTRA LONG','SUPER LONG']),'LONG',
                                  SELMA_DF_map['Length'] ))

duty_free_volumes = df_vols.copy()
duty_free_volumes['key'] = duty_free_volumes['CR_BrandId'].astype('str') + '-' + duty_free_volumes['Item per Bundle'].astype('str')
category_list = base_list.copy()
category_list['key'] =category_list['CR_BrandId'].astype('str') + '-' + category_list['Item per Bundle'].astype('str')

duty_free_volumes2 = duty_free_volumes[['DF_Market','Location','TMO','CR_BrandId','SKU',f"{current_year} Volume"]]
tobacco_range = category_list.merge(duty_free_volumes[['DF_Market', 'Location','key',f"{current_year} Volume"]], how = 'left', 
                                                    on = ['DF_Market', 'Location','key']).fillna(0)
tobacco_range['TMO'] = np.where(tobacco_range['TMO']!= 'PMI', 'Comp','PMI')
tobacco_range = tobacco_range[tobacco_range['CR_BrandId']!=0]

tobacco_range2 = tobacco_range[['DF_Market','Location','TMO','CR_BrandId','SKU',f"{current_year} Volume"]]
tobacco_range2 = pd.pivot_table(tobacco_range2, index = ['DF_Market','Location','TMO','CR_BrandId'],
               aggfunc={ f"{current_year} Volume": np.sum, 'SKU': np.count_nonzero}).reset_index()

selma_df_products = SELMA_DF_map.copy() 
selma_df_products = selma_df_products[selma_df_products['Product Category'] == 'Cigarettes'].reset_index()
selma_df_products_2 = selma_df_products[['DF_Market','Location', 'CR_BrandId']+brand_attributes ]
selma_df_products_3 = selma_df_products_2.drop_duplicates()
selma_df_products_3 = selma_df_products_3[selma_df_products_3['CR_BrandId']!= 0]

Market_Mix = selma_df_products_3.merge(tobacco_range2[['DF_Market', 'Location','CR_BrandId', 'TMO', 'SKU',
                                                    f"{current_year} Volume"]], how = 'left' , on = ['DF_Market', 'Location','CR_BrandId'])
Market_Mix = Market_Mix[Market_Mix['SKU'].notnull()]
Market_Mix = Market_Mix[Market_Mix['SKU']!=0]


all_market = pd.pivot_table(tobacco_range, index = ['DF_Market','Location','TMO'],  
                                                   aggfunc={ 'SKU': np.count_nonzero}).reset_index()
all_market = all_market.rename(columns = {'SKU': 'Total TMO'})
Market_Summary0 = pd.pivot_table(Market_Mix, index = ['DF_Market','Location', 'TMO']+brand_attributes,  
                                                   aggfunc={ f"{current_year} Volume": np.sum, 'SKU': np.sum}).reset_index()
Market_Summary = Market_Summary0.merge(all_market, how = 'left', on =['DF_Market','Location','TMO'] )
Market_Summary['SoM'] = round(Market_Summary['SKU']*100/Market_Summary['Total TMO'],1)
Market_Summary = Market_Summary[['DF_Market','Location','TMO']+ brand_attributes+['SKU','Total TMO', 'SoM']]

Market_Summary_PMI = Market_Summary[Market_Summary['TMO'] == 'PMI']
Market_Summary_Comp = Market_Summary[Market_Summary['TMO'] == 'Comp']
Market_Summary_PMI = Market_Summary_PMI.rename(columns= {'SoM':'SoM_PMI','SKU':'PMI_Seg_SKU', 'Total TMO': 'PMI Total'})
Market_Summary_Comp = Market_Summary_Comp.rename(columns= {'SoM':'SoM_Comp','SKU':'Comp_Seg_SKU', 'Total TMO': 'Comp Total'})
Market_Summary_Comp = Market_Summary_Comp[['DF_Market','Location']+ brand_attributes+ ['Comp_Seg_SKU','Comp Total','SoM_Comp']]
Market_Summary_PMI = Market_Summary_PMI[['DF_Market','Location']+ brand_attributes+['PMI_Seg_SKU','PMI Total','SoM_PMI']]

Market_Summary_Delta = Market_Summary_Comp.merge(Market_Summary_PMI[['DF_Market','Location','Flavor','Taste','Thickness',
                                                'Length','PMI_Seg_SKU','PMI Total','SoM_PMI']], how = 'outer', 
                                                 on = ['DF_Market','Location','Flavor','Taste','Thickness','Length']).fillna(0)

Market_Volume_Table = Market_Summary0.groupby(['DF_Market', 'Location']+ brand_attributes).sum(f"{current_year} Volume").reset_index()

Market = Market_Summary_Delta.merge(Market_Volume_Table[['DF_Market', 'Location']+ brand_attributes+ [f"{current_year} Volume"]] 
                                    ,how = 'left', on = ['DF_Market', 'Location']+ brand_attributes)
Market['SKU_Delta'] = Market['SoM_PMI'] - Market['SoM_Comp']

location = []
score = []
num_of_pmi_sku = []
num_of_comp_sku = []
pmi_cot = []
comp_cot = []

for i in Market['Location'].unique():
    looped_market = Market[Market['Location']== i]
    X, y = looped_market[[\"SoM_PMI\"]], looped_market[[\"SoM_Comp\"]]\n",
    model.fit(X, y)
    r_squared = model.score(X, y)
    market_score = round(r_squared*10,2)
    
    skunum =  max(Market[(Market['Location']== i)].iloc[:,-4],default=0)
    compsku =  max(Market[(Market['Location']== i)].iloc[:,-7],default=0)
    pmi_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']== 'PMI')].sum().iloc[-1].astype('int')
    comp_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']!= 'PMI')].sum().iloc[-1].astype('int')
    
    location.append(i)
    score.append(market_score)
    num_of_pmi_sku.append(skunum)
    num_of_comp_sku.append(compsku)
    pmi_cot.append(pmi_vol)
    comp_cot.append(comp_vol)

list_of_tuples = list(zip(location, score,num_of_pmi_sku,num_of_comp_sku,pmi_cot,comp_cot))
cat_b_scores = pd.DataFrame(list_of_tuples,columns=['Location', 'RSQ', 'NumPMI_SKU','NumComp_SKU','PMI Volume','Comp Volume']).fillna(0)

cat_c_scores = pd.DataFrame()

mrk_nat_map = pd.read_pickle('datasource/mrk_nat_map.pkl')
IATA_Location = pd.read_pickle('datasource/IATA_Location.pkl')
SELMA_dom_map = pd.read_pickle('datasource/SELMA_dom_map.pkl')
SELMA_DF_map = pd.read_pickle('datasource/SELMA_DF_map.pkl')
Pmidf_products = pd.read_pickle('datasource/Pmidf_products.pkl')
dom_prods_data = pd.read_pickle('datasource/dom_prods_data.pkl')
dom_ims_data = pd.read_pickle('datasource/dom_ims_data.pkl')
DomesticVolumes = pd.read_pickle('datasource/DomesticVolumes.pkl')
CF_data = pd.read_pickle('datasource/CF_data.pkl')
PAX_data = pd.read_pickle('datasource/PAX_data.pkl')
DF_Vol_data = pd.read_pickle('datasource/DF_Vol_data.pkl')

SELMA_dom_map['Length'] = np.where(SELMA_dom_map['Length'].isin(['REGULAR SIZE','REGULAR FILTER','SHORT SIZE','LONG FILTER']), 'KS',
                          np.where(SELMA_dom_map['Length'].isin(['LONGER THAN KS','100','LONG SIZE','EXTRA LONG','SUPER LONG']),'LONG',
                          SELMA_dom_map['Length']))
SELMA_dom_map['Thickness'] = np.where(SELMA_dom_map['Thickness']== 'FAT', 'STD',
                             SELMA_dom_map['Thickness'])

SELMA_dom_map = SELMA_dom_map.merge(dom_prods_data[['EBROMId']], how = 'left', on = 'EBROMId')

SELMA_DF_map = SELMA_DF_map.drop_duplicates(['CR_BrandId','Location'])
SELMA_DF_map['Length'] = np.where(SELMA_DF_map['Length'].isin(['REGULAR SIZE','REGULAR FILTER','SHORT SIZE','LONG FILTER','NAN']),'KS', 
                         np.where(SELMA_DF_map['Length'].isin(['LONGER THAN KS','100','LONG SIZE','EXTRA LONG','SUPER LONG']),'LONG',
                                  SELMA_DF_map['Length'] ))
DF_Vol_data = DF_Vol_data[DF_Vol_data['Year'] == current_year]
DF_Vol_data_cleared = DF_Vol_data[DF_Vol_data['CR_BrandId']!= 0 ]
DF_Vol_data_cleared = DF_Vol_data[DF_Vol_data['Product Category'] == 'Cigarettes' ]
DF_Vol_data_cleared = DF_Vol_data_cleared[DF_Vol_data_cleared['TMO'] == 'PMI']
base_list['key'] = base_list['Location'] + base_list['CR_BrandId'].astype('str')
DF_Vol_data_cleared['key'] = DF_Vol_data_cleared['Location'] + DF_Vol_data_cleared['CR_BrandId'].astype('str')
checklist = list(base_list['key'].unique())
DF_Vol_data_cleared = DF_Vol_data_cleared[DF_Vol_data_cleared['key'].isin(checklist)]
DF_Vol_data_cleared = DF_Vol_data_cleared.drop(columns= 'key')

DF_Vol_data_wLocation = DF_Vol_data_cleared.merge(IATA_Location,how='left', on ='Location')
DF_Vols = DF_Vol_data_wLocation.merge(SELMA_DF_map[['CR_BrandId','Location']+brand_attributes], 
                                      how = 'left', on = ['CR_BrandId','Location'])


dom_ims_data = dom_ims_data.groupby(time_dim + ['EBROMId']).sum('Volume').reset_index()

DomesticVolumesYearly = DomesticVolumes.groupby(time_dim +['Market', 'EBROMId']).sum('Volume').reset_index()
TotalDomMarkets  = DomesticVolumesYearly.groupby(time_dim + ['Market']).sum('Volume').reset_index()
DomesticSom = DomesticVolumesYearly.merge(TotalDomMarkets, how = 'left', on = time_dim+ ['Market'])
DomesticSom = DomesticSom.rename(columns = {'Volume_x': 'SKU_Vol', 'Volume_y': 'Market_Vol'})
DomesticSom = DomesticSom[time_dim + ['Market','SKU_Vol', 'Market_Vol' ]]
DomesticSom['SodRealDom']  = DomesticSom['SKU_Vol'] / DomesticSom['Market_Vol']


pax_d1 = PAX_data[time_dim + ['IATA', 'Market', 'Nationality', 'Pax']].copy()
pax_d2 = pax_d1.groupby(time_dim + ['IATA', 'Market', 'Nationality']).sum().reset_index()
pax_d3 = pax_d2.merge(mrk_nat_map, how='left', left_on ='Nationality',right_on='Nationalities')

cf_d2 = CF_data[['KFYear','Country','SmokingPrevelance','InboundAllowance','ADCStick','PurchaserRate']].copy()

cf_d2['ADCStick'] = cf_d2['ADCStick'].fillna(15.0)
cf_d2['InboundAllowance'] = cf_d2['InboundAllowance'].fillna(400.0)
cf_d2['PurchaserRate'] = np.where(cf_d2['PurchaserRate'] == cf_d2['PurchaserRate'], 
                                  cf_d2['PurchaserRate'], cf_d2['SmokingPrevelance'])

pax_d4 = pax_d3.merge(cf_d2, how='left',left_on=['Nationalities','Year'],right_on=['Country','KFYear'])

pax_d4['Pax'] = np.ceil(pax_d4['Pax'] * 1000)

pax_d4['LANU'] = pax_d4['Pax'] * pax_d4['SmokingPrevelance'] * 0.9 # * pax_d4['InboundAllowance']
pax_d4['LANU'] = np.ceil(pax_d4['LANU'])
pax_d4['InboundAllowance'] = pax_d4['InboundAllowance'].astype(float)
pax_d4['StickCons'] =  pax_d4['LANU'] * pax_d4['InboundAllowance']

pax_fin_ = pax_d4[time_dim + ['Market','IATA','Nationality',
                  'Countries','LANU','StickCons']].rename(columns={'Market':'DF_Market'})


pax_fin = pax_fin_.groupby(time_dim + ['DF_Market','IATA',
                                         'Nationality','Countries']).sum('StickCons').reset_index()

dom_attr = SELMA_dom_map[domestic_dimensions].merge(dom_prods_data[['EBROMId','TMO','Brand Family']], 
                                                    how='left',on='EBROMId').fillna('NaN')
dom_ims2 = dom_ims_data.merge(dom_attr,how='left',on='EBROMId')
dom_ims2 = dom_ims2[dom_ims2['Market'] != 'PMIDF']
dom_ims2 = dom_ims2[dom_ims2['EBROMId'] != 0]
dom_ims2 = dom_ims2[dom_ims2['EBROM'] == dom_ims2['EBROM']]
dom_ims2['Market'] =dom_ims2['Market'].replace('PRC', 'China') 
#dom_ims2['Market'] =dom_ims2['Market'].replace('Spain Mainland', 'Spain') 

dom_totals = dom_ims2.groupby(time_dim+['Market']).sum().reset_index().rename(columns={'Volume':'TotVol'})

dom_sov = dom_ims2.merge(dom_totals[time_dim+['Market','TotVol']], how='left', on=time_dim +['Market'])

dom_sov['SoDom'] = dom_sov['Volume'] / dom_sov['TotVol']

dom_fin = dom_sov[time_dim + domestic_dimensions + ['TMO','SoDom']].rename(columns={'Market':'Dom_Market'})

projected_vol_by_sku = pax_fin.merge(dom_fin, how='left',left_on = time_dim +['Countries'] ,
                            right_on= time_dim + ['Dom_Market'])
projected_vol_by_sku['Proj_Vol_bySKU'] = round(projected_vol_by_sku['SoDom'] * projected_vol_by_sku['StickCons'])
projected_vol_by_sku['Proj_LANU_bySKU'] = round(projected_vol_by_sku['SoDom'] * projected_vol_by_sku['LANU'])

projected_vol_by_prod_dim = projected_vol_by_sku.groupby(['IATA']+ dimension).agg(
    Proj_Vol_PG=('Proj_Vol_bySKU', np.sum), Proj_LANU_PG=('Proj_LANU_bySKU', np.sum)).reset_index()

proj_totVol = projected_vol_by_prod_dim.groupby(['IATA']).sum().reset_index().rename(columns={'Proj_Vol_PG':'Tot_proj_Vol'})
proj_SoM_PG = projected_vol_by_prod_dim.merge(proj_totVol[['IATA','Tot_proj_Vol']], how = 'left', on = ['IATA'])
proj_SoM_PG['Proj_SoM_PG'] =  proj_SoM_PG['Proj_Vol_PG'] / proj_SoM_PG['Tot_proj_Vol']

DFVol_IATA_bySKU = DF_Vols.groupby(['Year', 'IATA'] + dimension).sum('DF_Vol').reset_index()

Total_DFVol_byIATA = DFVol_IATA_bySKU.groupby(['Year','IATA']).sum().reset_index().rename(columns={'DF_Vol':'DFTot_Vol'})

DFSoM_IATA_bySKU = DFVol_IATA_bySKU.merge(Total_DFVol_byIATA[time_dim + ['IATA','DFTot_Vol']],
                                    how='left', on = time_dim + ['IATA'])

DFSoM_IATA_bySKU['DF_SoM_IATA_PG'] = DFSoM_IATA_bySKU['DF_Vol'] / DFSoM_IATA_bySKU['DFTot_Vol']

DFSoM_IATA_bySKU = DFSoM_IATA_bySKU[['IATA'] + dimension+ ['DF_Vol', 'DFTot_Vol', 'DF_SoM_IATA_PG']]

PARIS_output = proj_SoM_PG.merge(DFSoM_IATA_bySKU,how = 'outer',on = dimension + ['IATA']).fillna(0)

PARIS_output['DF_SoM_IATA_PG'] = PARIS_output['DF_SoM_IATA_PG'].fillna(0)
PARIS_output['Proj_SoM_PG'] = PARIS_output['Proj_SoM_PG'].fillna(0)
PARIS_output['Delta_SoS'] =  PARIS_output['Proj_SoM_PG'] - PARIS_output['DF_SoM_IATA_PG']

PARIS_output = PARIS_output[dimension+['IATA','DF_Vol','Proj_SoM_PG', 'DF_SoM_IATA_PG', 'Delta_SoS']]
PARIS_output = PARIS_output.merge(IATA_Location, how = 'left', on = 'IATA')
PARIS_output = PARIS_output[PARIS_output['Location'].notnull()]
PARIS_output = PARIS_output.rename(columns = {'DF_SoM_IATA_PG' : 'Real_So_Segment' ,'Proj_SoM_PG' : 'Ideal_So_Segment' })
PARIS_output = PARIS_output[PARIS_output['Ideal_So_Segment']>0.001]
PARIS_output = PARIS_output[['Location', 'IATA'] + brand_attributes + 
                            ['DF_Vol','Real_So_Segment','Ideal_So_Segment','Delta_SoS']]

location = []
score = []
num_of_pmi_sku = []
num_of_comp_sku = []
pmi_cot = []
comp_cot = []
for i in Market['Location'].unique():
    looped_market = Market[Market['Location']== i]
    X, y = looped_market[[\"SoM_PMI\"]], looped_market[[\"SoM_Comp\"]]\n",
    model.fit(X, y)
    r_squared = model.score(X, y)
    market_score = round(r_squared*10,2)
    
    skunum =  max(Market[(Market['Location']== i)].iloc[:,-4],default=0)
    compsku =  max(Market[(Market['Location']== i)].iloc[:,-7],default=0)
    pmi_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']== 'PMI')].sum().iloc[-1].astype('int')
    comp_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']!= 'PMI')].sum().iloc[-1].astype('int')
    
    location.append(i)
    score.append(market_score)
    num_of_pmi_sku.append(skunum)
    num_of_comp_sku.append(compsku)
    pmi_cot.append(pmi_vol)
    comp_cot.append(comp_vol)

list_of_tuples = list(zip(location, score,num_of_pmi_sku,num_of_comp_sku,pmi_cot,comp_cot))
cat_b_scores = pd.DataFrame(list_of_tuples,columns=['Location', 'RSQ', 'NumPMI_SKU','NumComp_SKU','PMI Volume','Comp Volume']).fillna(0)
cat_b_scores = cat_b_scores.rename(columns = {'RSQ' : 'Cat_B'})

cat_b_scores = cat_b_scores[['Location', 'Cat_B']]
cat_b_scores['Location'] = cat_b_scores['Location'].str.strip()
cat_c_scores = pd.DataFrame()


location = []
score = []

for i in PARIS_output['Location'].unique():
    looped_market = PARIS_output[PARIS_output['Location']== i]
    X, y = looped_market[[\"Real_So_Segment\"]], looped_market[[\"Ideal_So_Segment\"]]
    model.fit(X, y)
    r_squared = model.score(X, y)
    market_score = round(r_squared*10,2)
    
    
    location.append(i)
    score.append(market_score)
    # print(i)
list_of_tuples = list(zip(location, score))
cat_c_scores = pd.DataFrame(list_of_tuples,columns=['Location', 'RSQ']).fillna(0)

cat_c_scores = cat_c_scores.rename(columns= {'RSQ': 'Cat_C'})
cat_c_scores = cat_c_scores[['Location', 'Cat_C']]
cat_c_scores['Location'] = cat_c_scores['Location'].str.strip()

similarity_file = pd.read_excel('datasource/matrix_end_2023.xlsx')
iata_location= pd.read_pickle('datasource/IATA_Location.pkl')
df_vols = pd.read_pickle('datasource/cat_a_df_vols.pkl')
base_list= pd.read_pickle('datasource/base_list.pkl')

similarity_file1 = pd.melt(similarity_file, id_vars =['IATA'], var_name = 'Cluster' , value_name = 'Score')
similarity_file1 = similarity_file1[similarity_file1['Score'] < 1]
similarity_file2 = similarity_file1.sort_values(['IATA','Score'], ascending = False)
similarity_file2['Rank'] = similarity_file2.groupby('IATA').rank(method = 'first', ascending = False)['Score']
clusters = similarity_file2[similarity_file2.Rank <=4 ]

duty_free_volumes = df_vols.copy()
duty_free_volumes['key'] = duty_free_volumes['CR_BrandId'].astype('str') + '-' + duty_free_volumes['Item per Bundle'].astype('str')
category_list = base_list.copy()
category_list['key'] =category_list['CR_BrandId'].astype('str') + '-' + category_list['Item per Bundle'].astype('str')

duty_free_volumes2 = duty_free_volumes[['DF_Market','Location','TMO','CR_BrandId','SKU',f"{current_year} Volume"]]
tobacco_range = category_list.merge(duty_free_volumes[['DF_Market', 'Location','key',f"{current_year} Volume"]], how = 'left', 
                                                    on = ['DF_Market', 'Location','key']).fillna(0)
tobacco_range['TMO'] = np.where(tobacco_range['TMO']!= 'PMI', 'Comp','PMI')
tobacco_range = tobacco_range[tobacco_range['CR_BrandId']!=0]

tobacco_range2 = tobacco_range[['DF_Market','Location','TMO','CR_BrandId','SKU',f"{current_year} Volume"]]
tobacco_range2 = pd.pivot_table(tobacco_range2, index = ['DF_Market','Location','TMO','CR_BrandId'],
               aggfunc={ f"{current_year} Volume": np.sum, 'SKU': np.count_nonzero}).reset_index()
selma_df_products = SELMA_DF_map.copy() 
selma_df_products = selma_df_products[selma_df_products['Product Category'] == 'Cigarettes'].reset_index()
selma_df_products_2 = selma_df_products[['DF_Market','Location', 'CR_BrandId']+brand_attributes ]
selma_df_products_3 = selma_df_products_2.drop_duplicates()
selma_df_products_3 = selma_df_products_3[selma_df_products_3['CR_BrandId']!= 0]
selma_df_products_3 = selma_df_products_3[~selma_df_products_3['DF_Market'].isna()]

Market_Mix = selma_df_products_3.merge(tobacco_range2[['DF_Market', 'Location','CR_BrandId', 'TMO', 'SKU',
                                                    f"{current_year} Volume"]], how = 'left' , on = ['DF_Market', 'Location','CR_BrandId'])
Market_Mix = Market_Mix[Market_Mix['SKU'].notnull()]
Market_Mix = Market_Mix[Market_Mix['SKU']!=0]
Market_Mix = Market_Mix.merge(iata_location, how = 'left', on = 'Location')

all_market = pd.pivot_table(tobacco_range, index = ['DF_Market','Location','TMO'],  
                                                   aggfunc={ 'SKU': np.count_nonzero}).reset_index()
all_market = all_market.rename(columns = {'SKU': 'Total TMO'})
Market_Summary0 = pd.pivot_table(Market_Mix, index = ['DF_Market','IATA','Location', 'TMO']+brand_attributes,  
                                                   aggfunc={ f"{current_year} Volume": np.sum, 'SKU': np.sum}).reset_index()
Market_Summary = Market_Summary0.merge(all_market, how = 'left', on =['DF_Market','Location','TMO'] )
Market_Summary['SoM'] = round(Market_Summary['SKU']*100/Market_Summary['Total TMO'],1)
Market_Summary = Market_Summary[['DF_Market','IATA','Location','TMO']+ brand_attributes+['SKU','Total TMO', 'SoM']]

Market_Summary_PMI = Market_Summary[Market_Summary['TMO'] == 'PMI']
Market_Summary_PMI = Market_Summary_PMI[(Market_Summary_PMI['DF_Market'] != 'Spain DP') & (Market_Summary_PMI['DF_Market'] != 'France DP')]
Market_Summary_Comp = Market_Summary[Market_Summary['TMO'] == 'Comp']
Market_Summary_Comp = Market_Summary_Comp[(Market_Summary_Comp['DF_Market'] != 'Spain DP') & (Market_Summary_Comp['DF_Market'] != 'France DP')]

Market_Summary_PMI = Market_Summary_PMI.rename(columns= {'SoM':'SoM_PMI','SKU':'PMI_Seg_SKU', 'Total TMO': 'PMI Total'})
Market_Summary_Comp = Market_Summary_Comp.rename(columns= {'SoM':'SoM_Comp','SKU':'Comp_Seg_SKU', 'Total TMO': 'Comp Total'})
Market_Summary_Comp = Market_Summary_Comp[['DF_Market','IATA','Location']+ brand_attributes+ ['Comp_Seg_SKU','Comp Total','SoM_Comp']]
Market_Summary_PMI = Market_Summary_PMI[['DF_Market','IATA','Location']+ brand_attributes+['PMI_Seg_SKU','PMI Total','SoM_PMI']]

Market_Summary_Delta = Market_Summary_Comp.merge(Market_Summary_PMI[['DF_Market','IATA','Location','Flavor','Taste','Thickness',
                                                'Length','PMI_Seg_SKU','PMI Total','SoM_PMI']], how = 'outer', 
                                                 on = ['DF_Market','IATA','Location','Flavor','Taste','Thickness','Length']).fillna(0)

Market_Volume_Table = Market_Summary0.groupby(['DF_Market', 'Location']+ brand_attributes).sum(f"{current_year} Volume").reset_index()

Market = Market_Summary_Delta.merge(Market_Volume_Table[['DF_Market', 'Location']+ brand_attributes+ [f"{current_year} Volume"]] 
                                    ,how = 'left', on = ['DF_Market', 'Location']+ brand_attributes)
Market['SKU_Delta'] = Market['SoM_PMI'] - Market['SoM_Comp']

location = []
score = []
num_of_pmi_sku = []
num_of_comp_sku = []
pmi_cot = []
comp_cot = []

for i in Market['Location'].unique():
    looped_market = Market[Market['Location']== i]
    X, y = looped_market[[\"SoM_PMI\"]], looped_market[[\"SoM_Comp\"]]
    model.fit(X, y)
    r_squared = model.score(X, y)
    market_score = round(r_squared*10,2)
    
    skunum =  max(Market[(Market['Location']== i)].iloc[:,-4],default=0)
    compsku =  max(Market[(Market['Location']== i)].iloc[:,-7],default=0)
    pmi_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']== 'PMI')].sum().iloc[-1].astype('int')
    comp_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']!= 'PMI')].sum().iloc[-1].astype('int')
    
    location.append(i)
    score.append(market_score)
    num_of_pmi_sku.append(skunum)
    num_of_comp_sku.append(compsku)
    pmi_cot.append(pmi_vol)
    comp_cot.append(comp_vol)

list_of_tuples = list(zip(location, score,num_of_pmi_sku,num_of_comp_sku,pmi_cot,comp_cot))
cat_b_scores = pd.DataFrame(list_of_tuples,columns=['Location', 'RSQ', 'NumPMI_SKU','NumComp_SKU','PMI Volume','Comp Volume']).fillna(0)

cat_c_scores = pd.DataFrame()


pax_d1 = PAX_data[time_dim + ['IATA', 'Market', 'Nationality', 'Pax']].copy()
pax_d2 = pax_d1.groupby(time_dim + ['IATA', 'Market', 'Nationality']).sum().reset_index()
pax_d3 = pax_d2.merge(mrk_nat_map, how='left', left_on ='Nationality',right_on='Nationalities')

cf_d2 = CF_data[['KFYear','Country','SmokingPrevelance','InboundAllowance','ADCStick','PurchaserRate']].copy()

cf_d2['ADCStick'] = cf_d2['ADCStick'].fillna(15.0)
cf_d2['InboundAllowance'] = cf_d2['InboundAllowance'].fillna(400.0)
cf_d2['PurchaserRate'] = np.where(cf_d2['PurchaserRate'] == cf_d2['PurchaserRate'], 
                                  cf_d2['PurchaserRate'], cf_d2['SmokingPrevelance'])

pax_d4 = pax_d3.merge(cf_d2, how='left',left_on=['Nationalities','Year'],right_on=['Country','KFYear'])
pax_d4['Pax'] = np.ceil(pax_d4['Pax'] * 1000)
pax_d4['LANU'] = pax_d4['Pax'] * pax_d4['SmokingPrevelance'] * 0.9
pax_d4['LANU'] = np.ceil(pax_d4['LANU'])
pax_d4['InboundAllowance'] = pax_d4['InboundAllowance'].astype(float)
pax_d4['StickCons'] =  pax_d4['LANU'] * pax_d4['InboundAllowance']

pax_fin_ = pax_d4[time_dim + ['Market','IATA','Nationality',
                  'Countries','LANU','StickCons']].rename(columns={'Market':'DF_Market'})

pax_fin = pax_fin_.groupby(time_dim + ['DF_Market','IATA',
                                         'Nationality','Countries']).sum('StickCons').reset_index()

dom_attr = SELMA_dom_map[domestic_dimensions].merge(dom_prods_data[['EBROMId','TMO','Brand Family']], 
                                                    how='left',on='EBROMId').fillna('NaN')
dom_ims2 = dom_ims_data.merge(dom_attr,how='left',on='EBROMId')
dom_ims2 = dom_ims2[dom_ims2['Market'] != 'PMIDF']
dom_ims2 = dom_ims2[dom_ims2['EBROMId'] != 0]
dom_ims2 = dom_ims2[dom_ims2['EBROM'] == dom_ims2['EBROM']]
dom_ims2['Market'] =dom_ims2['Market'].replace('PRC', 'China') 

dom_totals = dom_ims2.groupby(time_dim+['Market']).sum().reset_index().rename(columns={'Volume':'TotVol'})
dom_sov = dom_ims2.merge(dom_totals[time_dim+['Market','TotVol']], how='left', on=time_dim +['Market'])
dom_sov['SoDom'] = dom_sov['Volume'] / dom_sov['TotVol']
dom_fin = dom_sov[time_dim + domestic_dimensions + ['TMO','SoDom']].rename(columns={'Market':'Dom_Market'})


projected_vol_by_sku = pax_fin.merge(dom_fin, how='left',left_on = time_dim +['Countries'] ,
                            right_on= time_dim + ['Dom_Market'])
projected_vol_by_sku['Proj_Vol_bySKU'] = round(projected_vol_by_sku['SoDom'] * projected_vol_by_sku['StickCons'])
projected_vol_by_sku['Proj_LANU_bySKU'] = round(projected_vol_by_sku['SoDom'] * projected_vol_by_sku['LANU'])


projected_vol_by_prod_dim = projected_vol_by_sku.groupby(['IATA']+ dimension).agg(
    Proj_Vol_PG=('Proj_Vol_bySKU', np.sum), Proj_LANU_PG=('Proj_LANU_bySKU', np.sum)).reset_index()

proj_totVol = projected_vol_by_prod_dim.groupby(['IATA']).sum().reset_index().rename(columns={'Proj_Vol_PG':'Tot_proj_Vol'})
proj_SoM_PG = projected_vol_by_prod_dim.merge(proj_totVol[['IATA','Tot_proj_Vol']], how = 'left', on = ['IATA'])
proj_SoM_PG['Proj_SoM_PG'] =  proj_SoM_PG['Proj_Vol_PG'] / proj_SoM_PG['Tot_proj_Vol']

DFVol_IATA_bySKU = DF_Vols.groupby(['Year', 'IATA'] + dimension).sum('DF_Vol').reset_index()

Total_DFVol_byIATA = DFVol_IATA_bySKU.groupby(['Year','IATA']).sum().reset_index().rename(columns={'DF_Vol':'DFTot_Vol'})

DFSoM_IATA_bySKU = DFVol_IATA_bySKU.merge(Total_DFVol_byIATA[time_dim + ['IATA','DFTot_Vol']],
                                    how='left', on = time_dim + ['IATA'])

DFSoM_IATA_bySKU['DF_SoM_IATA_PG'] = DFSoM_IATA_bySKU['DF_Vol'] / DFSoM_IATA_bySKU['DFTot_Vol']
DFSoM_IATA_bySKU = DFSoM_IATA_bySKU[['IATA'] + dimension+ ['DF_Vol', 'DFTot_Vol', 'DF_SoM_IATA_PG']]

PARIS_output = proj_SoM_PG.merge(DFSoM_IATA_bySKU,how = 'outer',on = dimension + ['IATA']).fillna(0)

PARIS_output['DF_SoM_IATA_PG'] = PARIS_output['DF_SoM_IATA_PG'].fillna(0)
PARIS_output['Proj_SoM_PG'] = PARIS_output['Proj_SoM_PG'].fillna(0)
PARIS_output['Delta_SoS'] =  PARIS_output['Proj_SoM_PG'] - PARIS_output['DF_SoM_IATA_PG']

PARIS_output = PARIS_output[dimension+['IATA','DF_Vol','Proj_SoM_PG', 'DF_SoM_IATA_PG', 'Delta_SoS']]
PARIS_output = PARIS_output.merge(IATA_Location, how = 'left', on = 'IATA')
PARIS_output = PARIS_output[PARIS_output['Location'].notnull()]
PARIS_output = PARIS_output.rename(columns = {'DF_SoM_IATA_PG' : 'Real_So_Segment' ,'Proj_SoM_PG' : 'Ideal_So_Segment' })
PARIS_output = PARIS_output[PARIS_output['Ideal_So_Segment']>0.001]
PARIS_output = PARIS_output[['Location', 'IATA'] + brand_attributes + 
                            ['DF_Vol','Real_So_Segment','Ideal_So_Segment','Delta_SoS']]


location = []
score = []

for i in PARIS_output['Location'].unique():
    looped_market = PARIS_output[PARIS_output['Location']== i]
    X, y = looped_market[[\"Real_So_Segment\"]], looped_market[[\"Ideal_So_Segment\"]]
    model.fit(X, y)
    r_squared = model.score(X, y)
    market_score = round(r_squared*10,2)
    
    
    location.append(i)
    score.append(market_score)

list_of_tuples = list(zip(location, score))
cat_c_scores = pd.DataFrame(list_of_tuples,columns=['Location', 'RSQ']).fillna(0)


cat_b_scores = cat_b_scores.rename(columns= {'RSQ': 'Cat_B'})
cat_b_scores = cat_b_scores[['Location', 'Cat_B']]
cat_b_scores['Location'] = cat_b_scores['Location'].str.strip()
cat_c_scores = cat_c_scores.rename(columns= {'RSQ': 'Cat_C'})
cat_c_scores = cat_c_scores[['Location', 'Cat_C']]
cat_c_scores['Location'] = cat_c_scores['Location'].str.strip()
cat_d_scores = pd.DataFrame()

similarity_file1 = pd.melt(similarity_file, id_vars =['IATA'], var_name = 'Cluster' , value_name = 'Score')
similarity_file1 = similarity_file1[similarity_file1['Score'] < 1]
similarity_file2 = similarity_file1.sort_values(['IATA','Score'], ascending = False)
similarity_file2['Rank'] = similarity_file2.groupby('IATA').rank(method = 'first', ascending = False)['Score']
clusters = similarity_file2[similarity_file2.Rank <=4 ]


duty_free_volumes2 = duty_free_volumes[['DF_Market','Location','TMO','CR_BrandId','SKU',f"{current_year} Volume"]]
tobacco_range = category_list.merge(duty_free_volumes[['DF_Market', 'Location','key',f"{current_year} Volume"]], how = 'left', 
                                                    on = ['DF_Market', 'Location','key']).fillna(0)
tobacco_range['TMO'] = np.where(tobacco_range['TMO']!= 'PMI', 'Comp','PMI')
tobacco_range = tobacco_range[tobacco_range['CR_BrandId']!=0]


tobacco_range2 = tobacco_range[['DF_Market','Location','TMO','CR_BrandId','SKU',f"{current_year} Volume"]]
tobacco_range2 = pd.pivot_table(tobacco_range2, index = ['DF_Market','Location','TMO','CR_BrandId'],
               aggfunc={ f"{current_year} Volume": np.sum, 'SKU': np.count_nonzero}).reset_index()

selma_df_products = SELMA_DF_map.copy() 
selma_df_products = selma_df_products[selma_df_products['Product Category'] == 'Cigarettes'].reset_index()
selma_df_products_2 = selma_df_products[['DF_Market','Location', 'CR_BrandId']+brand_attributes ]
selma_df_products_3 = selma_df_products_2.drop_duplicates()
selma_df_products_3 = selma_df_products_3[selma_df_products_3['CR_BrandId']!= 0]
selma_df_products_3 = selma_df_products_3[~selma_df_products_3['DF_Market'].isna()]
Market_Mix = selma_df_products_3.merge(tobacco_range2[['DF_Market', 'Location','CR_BrandId', 'TMO', 'SKU',
                                                    f"{current_year} Volume"]], how = 'left' , on = ['DF_Market', 'Location','CR_BrandId'])
Market_Mix = Market_Mix[Market_Mix['SKU'].notnull()]
Market_Mix = Market_Mix[Market_Mix['SKU']!=0]
Market_Mix = Market_Mix.merge(iata_location, how = 'left', on = 'Location')


all_market = pd.pivot_table(tobacco_range, index = ['DF_Market','Location','TMO'],  
                                                   aggfunc={ 'SKU': np.count_nonzero}).reset_index()
all_market = all_market.rename(columns = {'SKU': 'Total TMO'})
Market_Summary0 = pd.pivot_table(Market_Mix, index = ['DF_Market','IATA','Location', 'TMO']+brand_attributes,  
                                                   aggfunc={ f"{current_year} Volume": np.sum, 'SKU': np.sum}).reset_index()
Market_Summary = Market_Summary0.merge(all_market, how = 'left', on =['DF_Market','Location','TMO'] )
Market_Summary['SoM'] = round(Market_Summary['SKU']*100/Market_Summary['Total TMO'],1)
Market_Summary = Market_Summary[['DF_Market','IATA','Location','TMO']+ brand_attributes+['SKU','Total TMO', 'SoM']]


Market_Summary_PMI = Market_Summary[Market_Summary['TMO'] == 'PMI']
Market_Summary_PMI = Market_Summary_PMI[(Market_Summary_PMI['DF_Market'] != 'Spain DP') & (Market_Summary_PMI['DF_Market'] != 'France DP')]
Market_Summary_Comp = Market_Summary[Market_Summary['TMO'] == 'Comp']
Market_Summary_Comp = Market_Summary_Comp[(Market_Summary_Comp['DF_Market'] != 'Spain DP') & (Market_Summary_Comp['DF_Market'] != 'France DP')]

Market_Summary_PMI = Market_Summary_PMI.rename(columns= {'SoM':'SoM_PMI','SKU':'PMI_Seg_SKU', 'Total TMO': 'PMI Total'})
Market_Summary_Comp = Market_Summary_Comp.rename(columns= {'SoM':'SoM_Comp','SKU':'Comp_Seg_SKU', 'Total TMO': 'Comp Total'})
Market_Summary_Comp = Market_Summary_Comp[['DF_Market','IATA','Location']+ brand_attributes+ ['Comp_Seg_SKU','Comp Total','SoM_Comp']]
Market_Summary_PMI = Market_Summary_PMI[['DF_Market','IATA','Location']+ brand_attributes+['PMI_Seg_SKU','PMI Total','SoM_PMI']]
Market_Summary_Delta = Market_Summary_Comp.merge(Market_Summary_PMI[['DF_Market','IATA','Location','Flavor','Taste','Thickness',
                                                'Length','PMI_Seg_SKU','PMI Total','SoM_PMI']], how = 'outer', 
                                                 on = ['DF_Market','IATA','Location','Flavor','Taste','Thickness','Length']).fillna(0)
Market_Volume_Table = Market_Summary0.groupby(['DF_Market', 'Location']+ brand_attributes).sum(f"{current_year} Volume").reset_index()

Market = Market_Summary_Delta.merge(Market_Volume_Table[['DF_Market', 'Location']+ brand_attributes+ [f"{current_year} Volume"]] 
                                    ,how = 'left', on = ['DF_Market', 'Location']+ brand_attributes)
Market['SKU_Delta'] = Market['SoM_PMI'] - Market['SoM_Comp']

location = []
score = []
num_of_pmi_sku = []
num_of_comp_sku = []
pmi_cot = []
comp_cot = []
for i in Market['Location'].unique():
    looped_market = Market[Market['Location']== i]
    X, y = looped_market[[\"SoM_PMI\"]], looped_market[[\"SoM_Comp\"]]
    model.fit(X, y)
    r_squared = model.score(X, y)
    market_score = round(r_squared*10,2)
    
    skunum =  max(Market[(Market['Location']== i)].iloc[:,-4],default=0)
    compsku =  max(Market[(Market['Location']== i)].iloc[:,-7],default=0)
    pmi_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']== 'PMI')].sum().iloc[-1].astype('int')
    comp_vol = Market_Mix[(Market_Mix['Location']== i) & (Market_Mix['TMO']!= 'PMI')].sum().iloc[-1].astype('int')
    
    location.append(i)
    score.append(market_score)
    num_of_pmi_sku.append(skunum)
    num_of_comp_sku.append(compsku)
    pmi_cot.append(pmi_vol)
    comp_cot.append(comp_vol)

list_of_tuples = list(zip(location, score,num_of_pmi_sku,num_of_comp_sku,pmi_cot,comp_cot))
cat_b_scores = pd.DataFrame(list_of_tuples,columns=['Location', 'RSQ', 'NumPMI_SKU','NumComp_SKU','PMI Volume','Comp Volume']).fillna(0)
cat_b_scores = cat_b_scores.rename(columns = {'RSQ' : 'Cat_B'})
cat_b_scores = cat_b_scores[['Location', 'Cat_B']]
cat_b_scores['Location'] = cat_b_scores['Location'].str.strip()

cat_c_scores = pd.DataFrame()

location = []
score = []

for i in PARIS_output['Location'].unique():
    looped_market = PARIS_output[PARIS_output['Location']== i]
    X, y = looped_market[[\"Real_So_Segment\"]], looped_market[[\"Ideal_So_Segment\"]]
    model.fit(X, y)
    r_squared = model.score(X, y)
    market_score = round(r_squared*10,2)
    
    
    location.append(i)
    score.append(market_score)

list_of_tuples = list(zip(location, score))
cat_c_scores = pd.DataFrame(list_of_tuples,columns=['Location', 'RSQ']).fillna(0)

cat_c_scores = cat_c_scores.rename(columns= {'RSQ': 'Cat_C'})
cat_c_scores = cat_c_scores[['Location', 'Cat_C']]
cat_c_scores['Location'] = cat_c_scores['Location'].str.strip()


cat_d_scores = pd.DataFrame()
def calculate_score(row):
   
    selected_iata = clusters[clusters['IATA'] == row['IATA']]
    
    if len(selected_iata) == 0 :
        return 0
        
    cluster_iata = list(selected_iata.Cluster.unique())
    
    b = Market_Summary_PMI[Market_Summary_PMI['IATA'].isin(cluster_iata)]
    b['IATA'] = row['IATA']
    b = b[['IATA'] + brand_attributes + ['PMI_Seg_SKU']]
    b = b.groupby(by =['IATA'] + brand_attributes).sum(['PMI_Seg_SKU']).reset_index()
    b = b.rename(columns = {'PMI_Seg_SKU':'Cluster Segment'})

    c = Market_Summary_Comp[Market_Summary_Comp['IATA'].isin(cluster_iata)]
    c['IATA'] = row['IATA']
    c = c[['IATA'] + brand_attributes + ['Comp_Seg_SKU']]
    c = c.groupby(by = ['IATA'] + brand_attributes).sum(['Comp_Seg_SKU']).reset_index()
    c = c.rename(columns = {'Comp_Seg_SKU':'Cluster Segment'})
    
    d = pd.concat([b,c], ignore_index = True) 
    d = d.groupby(by = ['IATA'] +  brand_attributes).sum(['Cluster Segment']).reset_index()
    d_x =  d.groupby(by = ['IATA']).sum('Cluster Segment').reset_index()
    d_x = d_x.rename(columns = {'Cluster Segment': 'Cluster_Total'})
    d = d.merge(d_x, how = 'left', on = 'IATA')
    
    e = Market_Summary_PMI[Market_Summary_PMI['IATA'] == row['IATA']]
    e = e.drop(columns = ['SoM_PMI'])
    e = e.rename(columns = {'PMI_Seg_SKU': 'PMI SKU'})
    
    e = e.merge(d, how = 'outer', on = ['IATA'] + brand_attributes).fillna(0)
    
    e['PMI SKU %'] = np.where(e['PMI Total']>0, e['PMI SKU'] / e['PMI Total'],0)
    e['Cluster SKU %'] = np.where(e['Cluster_Total']>0, e['Cluster Segment'] / e['Cluster_Total'],0)
    e['SKU Delta'] = e['PMI SKU %'] - e['Cluster SKU %']
        
        X, y = e[['PMI SKU %']], e[['Cluster SKU %']]
        model.fit(X,y)
        r_squared = model.score(X,y)
        market_score = round(r_squared*10,2)
        return market_score

cat_d_scores['Score_D'] = Market_Summary_PMI.apply(calculate_score,axis = 1)
cat_d_scores = cat_d_scores[['Location','Score_D']].drop_duplicates()
cat_d_scores = cat_d_scores.rename(columns = {'Score_D': 'Cat_D'})
cat_d_scores['Location'] = cat_d_scores['Location'].str.strip()

final_table_0 =  cat_a_scores.merge(cat_b_scores, how = 'left', on = 'Location')
final_table_1 = final_table_0.merge(cat_c_scores, how = 'left', on = 'Location')
final_table_2 = final_table_1.merge(cat_d_scores, how = 'left', on = 'Location')
final_table_3 = final_table_2.fillna(0)
final_table_4 = final_table_3.copy()
cols_to_average = ['Cat_A','Cat_B','Cat_C','Cat_D']
final_table_4[cols_to_average] = final_table_4[cols_to_average].replace(10, pd.NA)

final_table_4['Avg_Score'] = final_table_4[cols_to_average].mean(axis=1, skipna = True)
final_table_4['Avg_Score'] = final_table_4['Avg_Score'].astype('float')
final_table_4 = final_table_4[final_table_4['Avg_Score']>0]
final_table_4[cols_to_average] = final_table_4[cols_to_average].replace(pd.NA,10)
final_table_4['Avg_Score'] = round(final_table_4['Avg_Score'],2)

Location_Volumes = pd.pivot_table(cat_a_df_vols, index = ['Location'], aggfunc={ f"{current_year} Volume": np.sum}).reset_index()
PMI_Volumes_0 = cat_a_df_vols[cat_a_df_vols['TMO'] == 'PMI']
PMI_Volumes = pd.pivot_table(PMI_Volumes_0, index = ['Location'], aggfunc={ f"{current_year} Volume": np.sum}).reset_index()
Location_Volumes = Location_Volumes.rename(columns = {f"{current_year} Volume" : 'Market_Volume'})
PMI_Volumes = PMI_Volumes.rename(columns = {f"{current_year} Volume" : 'PMI_Volume'})
final_table_5 = final_table_4.merge(Location_Volumes[['Location', 'Market_Volume']], how = 'left', on = 'Location').fillna(0)
final_table_5 = final_table_5.merge(PMI_Volumes[['Location', 'PMI_Volume']], how = 'left', on = 'Location').fillna(0)

final_table_5.to_excel(r'Location_Scores_Outputs\\{}scores_1.xlsx'.format(current_year), index = False)